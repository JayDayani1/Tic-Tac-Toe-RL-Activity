{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w0VQPg0E9xpY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3, 3))\n",
        "        self.current_player = 1\n",
        "        self.game_over = False\n",
        "\n",
        "    def get_valid_moves(self):\n",
        "        return np.argwhere(self.board == 0)\n",
        "\n",
        "    def make_move(self, row, col):\n",
        "        self.board[row, col] = self.current_player\n",
        "        self.current_player = -self.current_player\n",
        "\n",
        "    def check_winner(self):\n",
        "        # Check rows\n",
        "        for row in range(3):\n",
        "            if np.all(self.board[row, :] == 1) or np.all(self.board[row, :] == -1):\n",
        "                return self.board[row, 0]\n",
        "\n",
        "        # Check columns\n",
        "        for col in range(3):\n",
        "            if np.all(self.board[:, col] == 1) or np.all(self.board[:, col] == -1):\n",
        "                return self.board[0, col]\n",
        "\n",
        "        # Check diagonals\n",
        "        if np.all(np.diag(self.board) == 1) or np.all(np.diag(self.board) == -1):\n",
        "            return self.board[0, 0]\n",
        "\n",
        "        if np.all(np.diag(np.fliplr(self.board)) == 1) or np.all(np.diag(np.fliplr(self.board)) == -1):\n",
        "            return self.board[0, 2]\n",
        "\n",
        "        # No winner\n",
        "        return 0\n",
        "\n",
        "    def check_game_over(self):\n",
        "        if self.check_winner() != 0 or np.all(self.board != 0):\n",
        "            self.game_over = True\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, gamma, epsilon):\n",
        "        self.q_table = {}\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        state_str = state.tostring()  # Convert numpy array to string\n",
        "        if state_str not in self.q_table:\n",
        "            self.q_table[state_str] = {}\n",
        "        if action not in self.q_table[state_str]:\n",
        "            self.q_table[state_str][action] = 0\n",
        "        return self.q_table[state_str][action]\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        state_str = state.tostring()  # Convert numpy array to string\n",
        "        next_state_str = next_state.tostring()  # Convert numpy array to string\n",
        "        if state_str not in self.q_table:\n",
        "            self.q_table[state_str] = {}\n",
        "        if next_state_str not in self.q_table:\n",
        "            self.q_table[next_state_str] = {}\n",
        "\n",
        "        max_q_value = max(self.q_table[next_state_str].values()) if self.q_table[next_state_str] else 0\n",
        "        new_q_value = (1 - self.alpha) * self.get_q_value(state, action) + self.alpha * (reward + self.gamma * max_q_value)\n",
        "        self.q_table[state_str][action] = new_q_value\n",
        "\n",
        "    def get_action(self, state):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            # Choose a random action\n",
        "            row = random.randint(0, 2)\n",
        "            col = random.randint(0, 2)\n",
        "        else:\n",
        "            # Choose the best action based on Q-values\n",
        "            actions = [(i, j) for i in range(3) for j in range(3)]\n",
        "            q_values = [self.get_q_value(state, action) for action in actions]\n",
        "            max_q_value = max(q_values)\n",
        "            best_actions = [action for action, q_value in zip(actions, q_values) if q_value == max_q_value]\n",
        "            row, col = random.choice(best_actions)\n",
        "\n",
        "        return row, col\n"
      ],
      "metadata": {
        "id": "uF_4q-aZ9yQh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agent(agent, episodes):\n",
        "    for episode in range(episodes):\n",
        "        game = TicTacToe()\n",
        "\n",
        "        while not game.game_over:\n",
        "            # Get current state and choose action\n",
        "            state = game.board.copy()\n",
        "            action = agent.get_action(state)\n",
        "\n",
        "            # Make the chosen move\n",
        "            game.make_move(action[0], action[1])\n",
        "\n",
        "            # Check if the game is over\n",
        "            game.check_game_over()\n",
        "            winner = game.check_winner()\n",
        "\n",
        "            if winner == 1:\n",
        "                reward = 1  # Agent won\n",
        "            elif winner == -1:\n",
        "                reward = -1  # Agent lost\n",
        "            else:\n",
        "                reward = 0  # Draw\n",
        "\n",
        "            # Update Q-table\n",
        "            next_state = game.board.copy()\n",
        "            agent.update_q_table(state, tuple(action), reward, next_state)"
      ],
      "metadata": {
        "id": "aoTRPckP921S"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_game(agent):\n",
        "    game = TicTacToe()\n",
        "\n",
        "    while not game.game_over:\n",
        "        # Display the board\n",
        "        print(game.board)\n",
        "\n",
        "        if game.current_player == 1:\n",
        "            # Agent's turn\n",
        "            state = game.board.copy()\n",
        "            action = agent.get_action(state)\n",
        "            game.make_move(action[0], action[1])\n",
        "            print(\"Agent's move:\")\n",
        "            print(game.board)\n",
        "        else:\n",
        "            # Human's turn\n",
        "            row = int(input(\"Enter row (0-2): \"))\n",
        "            col = int(input(\"Enter column (0-2): \"))\n",
        "            game.make_move(row, col)\n",
        "            print(\"Your move:\")\n",
        "            print(game.board)\n",
        "\n",
        "        game.check_game_over()\n",
        "\n",
        "    winner = game.check_winner()\n",
        "\n",
        "    if winner == 1:\n",
        "        print(\"Agent wins!\")\n",
        "    elif winner == -1:\n",
        "        print(\"You win!\")\n",
        "    else:\n",
        "        print(\"It's a draw!\")\n",
        "\n",
        "# Create an instance of the agent\n",
        "agent = QLearningAgent(alpha=0.5, gamma=0.9, epsilon=0.1)\n",
        "\n",
        "# Train the agent\n",
        "train_agent(agent, episodes=10000)\n",
        "\n",
        "# Play against the trained agent\n",
        "play_game(agent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5sfIAkz-A88",
        "outputId": "0570444e-b9d3-46fd-bf8b-2b0e72c4231a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-30dfd658b26c>:12: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  state_str = state.tostring()  # Convert numpy array to string\n",
            "<ipython-input-19-30dfd658b26c>:20: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  state_str = state.tostring()  # Convert numpy array to string\n",
            "<ipython-input-19-30dfd658b26c>:21: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  next_state_str = next_state.tostring()  # Convert numpy array to string\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "Agent's move:\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Enter row (0-2): 0\n",
            "Enter column (0-2): 0\n",
            "Your move:\n",
            "[[-1.  0.  0.]\n",
            " [ 0.  1.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "[[-1.  0.  0.]\n",
            " [ 0.  1.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "Agent's move:\n",
            "[[-1.  0.  0.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  0.  0.]]\n",
            "[[-1.  0.  0.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  0.  0.]]\n",
            "Enter row (0-2): 0\n",
            "Enter column (0-2): 1\n",
            "Your move:\n",
            "[[-1. -1.  0.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  0.  0.]]\n",
            "[[-1. -1.  0.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  0.  0.]]\n",
            "Agent's move:\n",
            "[[-1. -1.  0.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  1.  0.]]\n",
            "[[-1. -1.  0.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  1.  0.]]\n",
            "Enter row (0-2): 0\n",
            "Enter column (0-2): 2\n",
            "Your move:\n",
            "[[-1. -1. -1.]\n",
            " [ 0.  1.  1.]\n",
            " [ 0.  1.  0.]]\n",
            "You win!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAi5Q9wFDMS0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}